# (17)*****************************Overfiting and underfiting in machine learning************************************

# -----Overfiting definition-----Overfitting happens when a model learns the detail and noise in the training data to the extent that it negatively impacts the performance of the model on new data. This means that the noise or random fluctuations in the training data is picked up and learned as concepts by the model

# -----Underfiting Definition----Underfitting is a scenario in data science where a data model is unable to capture the relationship between the input and output variables accurately, generating a high error rate on both the training set and unseen data.

# -----How to handle it----using 2 modules we handle the overfitting and underfitting-----
# -----(1)-Resampling
# -----(2)-Holding a validation dataset


# ----Resampling----Data is the currency of applied machine learning. ... Resampling is a methodology of economically using a data sample to improve the accuracy and quantify the uncertainty of a population parameter. Resampling methods, in fact, make use of a nested resampling method.


# -----Holding a validation dataset----Also called a “hold-out sample.” A dataset drawn from the same population as the training dataset that is not used to calculate the AVM valuations. The holdout dataset is used for testing. Cross-validation techniques allow sales in the training dataset to be reused as the holdout set.